{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import optuna\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import os \n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the DNN model with dropout and layer normalization\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, n_layers, n_neurons, dropout_rate):\n",
    "        super(DNN, self).__init__()\n",
    "        layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layers.append(nn.Linear(input_size, n_neurons))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.LayerNorm(n_neurons))\n",
    "            layers.append(nn.Dropout(p=dropout_rate))\n",
    "            input_size = n_neurons\n",
    "        layers.append(nn.Linear(input_size, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def dataset_func(X, y, device, rand_state):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.12, random_state=rand_state)\n",
    "\n",
    "    print(\"Train Dataset: {}\".format(X_train.shape))\n",
    "    print(\"Val Dataset: {}\".format(X_val.shape))\n",
    "    print(\"Test Dataset: {}\".format(X_test.shape))\n",
    "\n",
    "    # Convert data to tensors and move to GPU\n",
    "    X_train = torch.tensor(X_train, device=device).float()\n",
    "    X_val = torch.tensor(X_val, device=device).float()\n",
    "    X_test = torch.tensor(X_test, device=device).float() \n",
    "    \n",
    "    y_train = torch.tensor(y_train.reshape(-1, 1), device=device).float()\n",
    "    y_val = torch.tensor(y_val.reshape(-1, 1), device=device).float()\n",
    "    y_test = torch.tensor(y_test.reshape(-1, 1), device=device).float()\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def objective(X, y, rand_state, num_epoch):\n",
    "    def objective_inner(trial):\n",
    "        device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = dataset_func(X, y, device, rand_state)\n",
    "\n",
    "        input_size = X_train.size(1)\n",
    "\n",
    "        n_layers = trial.suggest_int('n_layers', 1, 5)\n",
    "        n_neurons = trial.suggest_int('n_neurons', 1, 100)\n",
    "        dropout_rate = round(trial.suggest_uniform('dropout_rate', 0.0, 0.9), 5)\n",
    "        learning_rate = round(trial.suggest_loguniform('learning_rate', 1e-5, 1e-1), 5)\n",
    "\n",
    "        model = DNN(input_size, n_layers, n_neurons, dropout_rate).to(device)\n",
    "        criterion = nn.MSELoss() \n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epoch):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    return objective_inner\n",
    "\n",
    "def get_all_metrics(best_params, rand_state, num_epoch):\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = dataset_func(X, y, device, rand_state)\n",
    "\n",
    "    input_size = X_train.size(1)\n",
    "\n",
    "    best_n_layers = best_params['n_layers']\n",
    "    best_n_neurons = best_params['n_neurons']\n",
    "    best_dropout_rate = best_params['dropout_rate']\n",
    "    best_learning_rate = best_params['learning_rate']\n",
    "\n",
    "    model = DNN(input_size, best_n_layers, best_n_neurons, best_dropout_rate).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_learning_rate)\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss = loss.item()\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            val_loss = criterion(val_outputs, y_val).item()\n",
    "            val_loss_history.append(val_loss)\n",
    "\n",
    "    num_epoch_plot = num_epoch + 1\n",
    "    plt.plot(range(1, num_epoch_plot), train_loss_history, label='Train Loss')\n",
    "    plt.plot(range(1, num_epoch_plot), val_loss_history, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_train)\n",
    "        train_rmse = math.sqrt(criterion(outputs, y_train).item())\n",
    "        train_r2 = r2_score(y_train.cpu().numpy(), outputs.cpu().numpy())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)\n",
    "        val_rmse = math.sqrt(criterion(outputs, y_val).item())\n",
    "        val_r2 = r2_score(y_val.cpu().numpy(), outputs.cpu().numpy())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        test_rmse = math.sqrt(criterion(outputs, y_test).item())\n",
    "        test_r2 = r2_score(y_test.cpu().numpy(), outputs.cpu().numpy())\n",
    "\n",
    "    return train_rmse, val_rmse, test_rmse, train_r2, val_r2, test_r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('ATT_ind.csv',encoding='ISO-8859-1')\n",
    "df\n",
    "\n",
    "# Convert categorical data to one-hot encoded data\n",
    "df_ohe = pd.get_dummies(df, columns=['alkene', 'ligand', 'substrate'], drop_first=True)\n",
    "df_ohe = df_ohe.replace({True: 1, False: 0})\n",
    "df_ohe\n",
    "\n",
    "X = np.array(df_ohe.iloc[:,1:])\n",
    "y=np.array(df_ohe['ee']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9294944",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "best_params_app = []\n",
    "#rand_state_list = [5,10,15]\n",
    "\n",
    "# Set random state\n",
    "rand_state_list = [i for i in range(0,30)]\n",
    "\n",
    "for i in rand_state_list:\n",
    "    num_epoch = 300\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective(X, y, i, num_epoch), n_trials=50)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_accuracy = study.best_value\n",
    "\n",
    "    best_params = study.best_params\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Accuracy:\", best_accuracy)\n",
    "\n",
    "    accuracy = get_all_metrics(best_params, i, num_epoch)\n",
    "    best_params_app.append(best_params)\n",
    "    metrics.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the train, valid, and test accuracy from the accuracy_list\n",
    "train_accuracy = [item[0] for item in metrics]\n",
    "valid_accuracy = [item[1] for item in metrics]\n",
    "test_accuracy = [item[2] for item in metrics]\n",
    "\n",
    "train_top_k = [item[3] for item in metrics]\n",
    "valid_top_k = [item[4] for item in metrics]\n",
    "test_top_k = [item[5] for item in metrics]\n",
    "\n",
    "# Create a dictionary from the accuracy values\n",
    "data_rs = {'Split': rand_state_list,\n",
    "        'Train RMSE': train_accuracy,\n",
    "        'Validation RMSE': valid_accuracy,\n",
    "        'Test RMSE': test_accuracy,\n",
    "        'Train_R2': train_top_k,\n",
    "        'Valid_R2': valid_top_k,\n",
    "        'Test_R2': test_top_k,\n",
    "        'Parameters': best_params_app}\n",
    "# Create a pandas DataFrame\n",
    "dff_result = pd.DataFrame(data_rs)\n",
    "dff_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c9a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_result.to_csv('performance_file.csv', index =None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn_suzuki",
   "language": "python",
   "name": "dnn_suzuki"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
